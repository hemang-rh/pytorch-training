{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0352b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports, configuration, GPU detection, and GPU sampler\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import threading\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"tqdm\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# PARAMS (tunable in one place)\n",
    "# -----------------------------\n",
    "PARAMS = {\n",
    "    \"EPOCHS\": 5,\n",
    "    \"BATCH_SIZE\": 512,\n",
    "    \"IMAGE_SIZE\": 224,\n",
    "    \"NUM_CLASSES\": 1000,\n",
    "    \"NUM_SAMPLES\": 200_000,\n",
    "    \"MODEL_SIZE\": \"small\",\n",
    "    \"USE_AMP\": True,\n",
    "    \"GRAD_ACCUM_STEPS\": 1,\n",
    "    \"NUM_GPUS_TO_USE\": None,\n",
    "    \"WARMUP_STEPS\": 500,\n",
    "    \"BASE_LR\": 0.1,\n",
    "    \"WEIGHT_DECAY\": 1e-4,\n",
    "    \"MOMENTUM\": 0.9,\n",
    "    \"AUGMENT_NOISE\": True,\n",
    "    \"LABEL_SMOOTHING\": 0.05,\n",
    "    \"VARY_BATCH_SIZE_SCHEDULE\": True,\n",
    "    \"BATCH_SCHEDULE_MULTIPLIERS\": [1, 1, 2, 2, 3],\n",
    "    \"UTIL_SAMPLING_INTERVAL_SEC\": 1.0,\n",
    "    \"CSV_PATH\": \"/opt/app-root/src/data/gpu_samples.csv\",\n",
    "    \"SEED\": 42\n",
    "}\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(PARAMS[\"SEED\"])\n",
    "\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "WORLD_SIZE = int(os.environ.get(\"WORLD_SIZE\", \"1\"))\n",
    "USING_DDP = WORLD_SIZE > 1\n",
    "\n",
    "if IS_CUDA:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def gpu_inventory():\n",
    "    count = torch.cuda.device_count() if IS_CUDA else 0\n",
    "    print(f\"CUDA available: {IS_CUDA} | Visible GPUs: {count}\")\n",
    "    if count > 0:\n",
    "        for i in range(count):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            total_mem_gb = props.total_memory / (1024**3)\n",
    "            print(f\"  GPU {i}: {props.name} | {total_mem_gb:.2f} GB\")\n",
    "    return count\n",
    "\n",
    "VISIBLE_GPUS = gpu_inventory()\n",
    "if PARAMS[\"NUM_GPUS_TO_USE\"] is None:\n",
    "    PARAMS[\"NUM_GPUS_TO_USE\"] = VISIBLE_GPUS\n",
    "NUM_GPUS_TO_USE = min(PARAMS[\"NUM_GPUS_TO_USE\"], VISIBLE_GPUS) if IS_CUDA else 0\n",
    "\n",
    "if USING_DDP and NUM_GPUS_TO_USE > 0:\n",
    "    print(\"DDP environment detected. DataParallel skipped.\")\n",
    "\n",
    "if NUM_GPUS_TO_USE > 1 and not USING_DDP:\n",
    "    print(f\"Using DataParallel across {NUM_GPUS_TO_USE} GPUs.\")\n",
    "elif NUM_GPUS_TO_USE == 1:\n",
    "    print(\"Running on single GPU.\")\n",
    "elif NUM_GPUS_TO_USE == 0:\n",
    "    print(\"Running on CPU.\")\n",
    "\n",
    "PRIMARY_DEVICE = torch.device(\"cuda:0\") if NUM_GPUS_TO_USE > 0 else torch.device(\"cpu\")\n",
    "\n",
    "class GPUSampler:\n",
    "    def __init__(self, interval_sec: float = 1.0):\n",
    "        self.interval = interval_sec\n",
    "        self._stop = threading.Event()\n",
    "        self.samples: List[Dict] = []\n",
    "        self._thread: Optional[threading.Thread] = None\n",
    "        self.use_pynvml = False\n",
    "        self.nvidia_smi_ok = False\n",
    "        self._init_backends()\n",
    "\n",
    "    def _init_backends(self):\n",
    "        if not IS_CUDA or torch.cuda.device_count() == 0:\n",
    "            return\n",
    "        try:\n",
    "            import pynvml\n",
    "            pynvml.nvmlInit()\n",
    "            self._pynvml = pynvml\n",
    "            self.use_pynvml = True\n",
    "            self._nvml_handles = [\n",
    "                self._pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "                for i in range(torch.cuda.device_count())\n",
    "            ]\n",
    "            print(\"GPUSampler: Using PyNVML.\")\n",
    "            return\n",
    "        except Exception:\n",
    "            self.use_pynvml = False\n",
    "        try:\n",
    "            subprocess.run([\"nvidia-smi\", \"-L\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "            self.nvidia_smi_ok = True\n",
    "            print(\"GPUSampler: Using nvidia-smi fallback.\")\n",
    "        except Exception:\n",
    "            self.nvidia_smi_ok = False\n",
    "            print(\"GPUSampler: GPU sampling disabled.\")\n",
    "\n",
    "    def start(self):\n",
    "        if (not self.use_pynvml and not self.nvidia_smi_ok) or NUM_GPUS_TO_USE == 0:\n",
    "            return\n",
    "        self._stop.clear()\n",
    "        self._thread = threading.Thread(target=self._run, daemon=True)\n",
    "        self._thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if self._thread is None:\n",
    "            return\n",
    "        self._stop.set()\n",
    "        self._thread.join()\n",
    "\n",
    "    def _run(self):\n",
    "        while not self._stop.is_set():\n",
    "            timestamp = datetime.now(timezone.utc).isoformat()\n",
    "            try:\n",
    "                if self.use_pynvml:\n",
    "                    for i, handle in enumerate(self._nvml_handles):\n",
    "                        util = self._pynvml.nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "                        mem = self._pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                        self.samples.append({\n",
    "                            \"ts\": timestamp, \"gpu_index\": i,\n",
    "                            \"utilization_pct\": float(util),\n",
    "                            \"mem_used_mib\": float(mem.used) / (1024**2),\n",
    "                            \"mem_total_mib\": float(mem.total) / (1024**2),\n",
    "                        })\n",
    "                elif self.nvidia_smi_ok:\n",
    "                    result = subprocess.run(\n",
    "                        [\"nvidia-smi\", \"--query-gpu=index,utilization.gpu,memory.used,memory.total\",\n",
    "                         \"--format=csv,noheader,nounits\"],\n",
    "                        stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True, text=True\n",
    "                    )\n",
    "                    for line in result.stdout.strip().splitlines():\n",
    "                        idx, util, mem_used, mem_total = [x.strip() for x in line.split(\",\")]\n",
    "                        self.samples.append({\n",
    "                            \"ts\": timestamp, \"gpu_index\": int(idx),\n",
    "                            \"utilization_pct\": float(util),\n",
    "                            \"mem_used_mib\": float(mem_used),\n",
    "                            \"mem_total_mib\": float(mem_total),\n",
    "                        })\n",
    "            except Exception:\n",
    "                pass\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def save_csv(self, path: str):\n",
    "        if len(self.samples) == 0:\n",
    "            return\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"ts\", \"gpu_index\", \"utilization_pct\", \"mem_used_mib\", \"mem_total_mib\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.samples)\n",
    "\n",
    "    def summarize(self):\n",
    "        if len(self.samples) == 0:\n",
    "            return {}\n",
    "        by_gpu: Dict[int, List[Dict]] = {}\n",
    "        for row in self.samples:\n",
    "            by_gpu.setdefault(row[\"gpu_index\"], []).append(row)\n",
    "        summary = {}\n",
    "        for gpu_idx, rows in by_gpu.items():\n",
    "            avg_util = sum(r[\"utilization_pct\"] for r in rows) / len(rows)\n",
    "            max_util = max(r[\"utilization_pct\"] for r in rows)\n",
    "            avg_mem = sum(r[\"mem_used_mib\"] for r in rows) / len(rows)\n",
    "            max_mem = max(r[\"mem_used_mib\"] for r in rows)\n",
    "            summary[gpu_idx] = {\n",
    "                \"avg_util_pct\": avg_util,\n",
    "                \"max_util_pct\": max_util,\n",
    "                \"avg_mem_used_mib\": avg_mem,\n",
    "                \"max_mem_used_mib\": max_mem,\n",
    "                \"mem_total_mib\": rows[-1][\"mem_total_mib\"],\n",
    "            }\n",
    "        return summary\n",
    "\n",
    "gpu_sampler = GPUSampler(interval_sec=PARAMS[\"UTIL_SAMPLING_INTERVAL_SEC\"])\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f0bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model, synthetic dataset, dataloaders (with variable batch-size schedule support)\n",
    "\n",
    "# -----------------------------\n",
    "# Synthetic dataset\n",
    "# -----------------------------\n",
    "class RandomImageDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size, num_classes, augment_noise=True):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.augment_noise = augment_noise\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Random images ~ N(0,1)\n",
    "        x = torch.randn(3, self.image_size, self.image_size)\n",
    "        if self.augment_noise:\n",
    "            # small per-sample noise to change loss dynamics\n",
    "            x += 0.01 * torch.randn_like(x)\n",
    "        # Random labels each time (prevents memorization + non-constant loss)\n",
    "        y = torch.randint(low=0, high=self.num_classes, size=(1,)).item()\n",
    "        return x, y\n",
    "\n",
    "# -----------------------------\n",
    "# Simple scalable ConvNet\n",
    "# -----------------------------\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, size=\"small\", num_classes=1000):\n",
    "        super().__init__()\n",
    "        # width/depth scale by size\n",
    "        cfg = {\n",
    "            \"tiny\":  (32, 3),\n",
    "            \"small\": (64, 4),\n",
    "            \"base\":  (96, 6),\n",
    "            \"large\": (128, 8),\n",
    "        }[size]\n",
    "\n",
    "        width, depth = cfg\n",
    "        layers = []\n",
    "        in_ch = 3\n",
    "        for i in range(depth):\n",
    "            out_ch = width * (2 ** (i // 2))  # grow slowly\n",
    "            stride = 2 if i % 2 == 1 else 1   # occasional downsampling\n",
    "            layers.append(ConvBlock(in_ch, out_ch, k=3, s=stride, p=1))\n",
    "            in_ch = out_ch\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_ch, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.head(x)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataloader factory (supports epoch-specific batch size)\n",
    "# -----------------------------\n",
    "def make_loader(dataset, batch_size, use_cuda):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=4 if use_cuda else 2,\n",
    "        pin_memory=use_cuda\n",
    "    )\n",
    "\n",
    "dataset = RandomImageDataset(\n",
    "    num_samples=PARAMS[\"NUM_SAMPLES\"],\n",
    "    image_size=PARAMS[\"IMAGE_SIZE\"],\n",
    "    num_classes=PARAMS[\"NUM_CLASSES\"],\n",
    "    augment_noise=PARAMS[\"AUGMENT_NOISE\"],\n",
    ")\n",
    "\n",
    "# Prepare initial loader (may be replaced per-epoch if schedule enabled)\n",
    "current_batch_size = PARAMS[\"BATCH_SIZE\"]\n",
    "train_loader = make_loader(dataset, current_batch_size, IS_CUDA)\n",
    "\n",
    "# Build model\n",
    "model = TinyCNN(size=PARAMS[\"MODEL_SIZE\"], num_classes=PARAMS[\"NUM_CLASSES\"])\n",
    "\n",
    "# DataParallel wrapping if multi-GPU (and not DDP)\n",
    "if NUM_GPUS_TO_USE > 1 and not USING_DDP:\n",
    "    device_ids = list(range(NUM_GPUS_TO_USE))\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "model = model.to(PRIMARY_DEVICE)\n",
    "\n",
    "# Optimizer and Loss\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=PARAMS[\"BASE_LR\"],\n",
    "                      momentum=PARAMS[\"MOMENTUM\"],\n",
    "                      weight_decay=PARAMS[\"WEIGHT_DECAY\"])\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=PARAMS[\"LABEL_SMOOTHING\"])\n",
    "\n",
    "# AMP scaler\n",
    "scaler = GradScaler(enabled=PARAMS[\"USE_AMP\"])\n",
    "\n",
    "print(\"Model and dataloader ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Training loop with progress bar, LR schedule, grad accumulation, memory/metering\n",
    "\n",
    "def cosine_after_warmup(step, warmup_steps, total_steps, base_lr):\n",
    "    if step < warmup_steps:\n",
    "        return base_lr * float(step + 1) / float(max(1, warmup_steps))\n",
    "    # cosine from warmup_end..total_steps\n",
    "    t = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "    return base_lr * 0.5 * (1.0 + math.cos(math.pi * t))\n",
    "\n",
    "def cuda_sync():\n",
    "    if IS_CUDA:\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def mem_snapshot_per_gpu(tag: str):\n",
    "    if not IS_CUDA or NUM_GPUS_TO_USE == 0:\n",
    "        return\n",
    "    print(f\"[Memory Snapshot] {tag}\")\n",
    "    for i in range(NUM_GPUS_TO_USE):\n",
    "        torch.cuda.synchronize(i)\n",
    "        allocated = torch.cuda.memory_allocated(i) / (1024**2)\n",
    "        reserved = torch.cuda.memory_reserved(i) / (1024**2)\n",
    "        max_alloc = torch.cuda.max_memory_allocated(i) / (1024**2)\n",
    "        max_resv  = torch.cuda.max_memory_reserved(i) / (1024**2)\n",
    "        print(f\"  GPU {i}: allocated={allocated:.1f} MiB | reserved={reserved:.1f} MiB | \"\n",
    "              f\"max_alloc={max_alloc:.1f} MiB | max_reserved={max_resv:.1f} MiB\")\n",
    "\n",
    "def train():\n",
    "    global train_loader, current_batch_size\n",
    "\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = steps_per_epoch * PARAMS[\"EPOCHS\"]\n",
    "    step_idx = 0\n",
    "\n",
    "    # Start GPU sampler\n",
    "    gpu_sampler.start()\n",
    "\n",
    "    overall_start = time.time()\n",
    "    running_total_images = 0\n",
    "    last_epoch_stats = {}\n",
    "\n",
    "    for epoch in range(PARAMS[\"EPOCHS\"]):\n",
    "        # Optionally vary batch size to demonstrate memory changes\n",
    "        if PARAMS[\"VARY_BATCH_SIZE_SCHEDULE\"]:\n",
    "            mult = PARAMS[\"BATCH_SCHEDULE_MULTIPLIERS\"][epoch % len(PARAMS[\"BATCH_SCHEDULE_MULTIPLIERS\"])]\n",
    "            new_bs = max(1, PARAMS[\"BATCH_SIZE\"] * mult)\n",
    "            if new_bs != current_batch_size:\n",
    "                current_batch_size = new_bs\n",
    "                train_loader = make_loader(dataset, current_batch_size, IS_CUDA)\n",
    "                steps_per_epoch = len(train_loader)\n",
    "                total_steps = steps_per_epoch * (PARAMS[\"EPOCHS\"] - epoch) + step_idx\n",
    "                print(f\"[Epoch {epoch+1}] Adjusted batch size to {current_batch_size}. Steps/epoch: {steps_per_epoch}\")\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss_sum = 0.0\n",
    "        epoch_images = 0\n",
    "\n",
    "        # Reset peak memory stats each epoch for clearer snapshots\n",
    "        if IS_CUDA:\n",
    "            for i in range(NUM_GPUS_TO_USE):\n",
    "                torch.cuda.reset_peak_memory_stats(i)\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{PARAMS['EPOCHS']}\")\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        for step_in_epoch, (images, targets) in pbar:\n",
    "            images = images.to(PRIMARY_DEVICE, non_blocking=True) if IS_CUDA else images\n",
    "            targets = targets.to(PRIMARY_DEVICE, non_blocking=True) if IS_CUDA else targets\n",
    "\n",
    "            # Compute scheduled LR\n",
    "            lr = cosine_after_warmup(step_idx, PARAMS[\"WARMUP_STEPS\"], total_steps, PARAMS[\"BASE_LR\"])\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr\n",
    "\n",
    "            # Forward + loss (AMP optional)\n",
    "            with autocast(enabled=PARAMS[\"USE_AMP\"] and IS_CUDA):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            # Grad scaling/accumulation\n",
    "            loss_to_report = loss.detach().item()\n",
    "            epoch_loss_sum += loss_to_report\n",
    "            batch_size_effective = images.size(0)\n",
    "            epoch_images += batch_size_effective\n",
    "            running_total_images += batch_size_effective\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step_in_epoch + 1) % PARAMS[\"GRAD_ACCUM_STEPS\"] == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Progress bar metrics\n",
    "            # Compute instantaneous imgs/sec (sync for accurate timing)\n",
    "            cuda_sync()\n",
    "            elapsed_epoch = max(1e-6, time.time() - epoch_start)\n",
    "            imgs_per_sec = epoch_images / elapsed_epoch\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss_to_report:.4f}\",\n",
    "                \"lr\": f\"{lr:.4e}\",\n",
    "                \"ips\": f\"{imgs_per_sec:.1f}\"\n",
    "            })\n",
    "\n",
    "            step_idx += 1\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = epoch_loss_sum / max(1, len(train_loader))\n",
    "        cuda_sync()\n",
    "        imgs_per_sec_epoch = epoch_images / max(1e-6, epoch_time)\n",
    "\n",
    "        print(f\"\\n[Epoch {epoch+1} Summary] \"\n",
    "              f\"time={epoch_time:.2f}s | avg_loss={avg_loss:.4f} | throughput={imgs_per_sec_epoch:.1f} img/s \"\n",
    "              f\"| batch_size={current_batch_size}\")\n",
    "\n",
    "        mem_snapshot_per_gpu(f\"End of Epoch {epoch+1}\")\n",
    "\n",
    "        last_epoch_stats = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"time_sec\": epoch_time,\n",
    "            \"avg_loss\": avg_loss,\n",
    "            \"throughput_img_per_sec\": imgs_per_sec_epoch,\n",
    "            \"batch_size\": current_batch_size\n",
    "        }\n",
    "\n",
    "    total_time = time.time() - overall_start\n",
    "    gpu_sampler.stop()\n",
    "\n",
    "    return {\n",
    "        \"total_time_sec\": total_time,\n",
    "        \"total_images\": running_total_images,\n",
    "        \"last_epoch\": last_epoch_stats\n",
    "    }\n",
    "\n",
    "train_stats = train()\n",
    "print(\"Training run complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Save GPU samples, print per-GPU summary and final metrics\n",
    "\n",
    "# Save CSV (if any samples)\n",
    "gpu_sampler.save_csv(PARAMS[\"CSV_PATH\"])\n",
    "\n",
    "summary = gpu_sampler.summarize()\n",
    "if summary:\n",
    "    print(\"\\nPer-GPU Utilization & Memory Summary:\")\n",
    "    for gpu_idx in sorted(summary.keys()):\n",
    "        s = summary[gpu_idx]\n",
    "        print(f\"  GPU {gpu_idx}: \"\n",
    "              f\"avg_util={s['avg_util_pct']:.1f}% | max_util={s['max_util_pct']:.1f}% | \"\n",
    "              f\"avg_mem={s['avg_mem_used_mib']:.0f} MiB | max_mem={s['max_mem_used_mib']:.0f} MiB \"\n",
    "              f\"(total={s['mem_total_mib']:.0f} MiB)\")\n",
    "\n",
    "    # Effective average across used GPUs\n",
    "    used_gpu_indices = [i for i in summary.keys() if i < NUM_GPUS_TO_USE]\n",
    "    if used_gpu_indices:\n",
    "        eff_avg_util = sum(summary[i]['avg_util_pct'] for i in used_gpu_indices) / len(used_gpu_indices)\n",
    "        print(f\"\\nEffective average utilization across {len(used_gpu_indices)} GPU(s): {eff_avg_util:.1f}%\")\n",
    "else:\n",
    "    if NUM_GPUS_TO_USE == 0:\n",
    "        print(\"\\nNo GPU detected; utilization sampling not available.\")\n",
    "    else:\n",
    "        print(\"\\nGPU sampler produced no samples (unexpected).\")\n",
    "\n",
    "# Final training summary\n",
    "total_time = train_stats[\"total_time_sec\"]\n",
    "total_images = train_stats[\"total_images\"]\n",
    "last_epoch = train_stats[\"last_epoch\"]\n",
    "imgs_per_sec_total = total_images / max(1e-6, total_time)\n",
    "\n",
    "print(\"\\n=== Final Training Summary ===\")\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Total images seen: {total_images}\")\n",
    "print(f\"Overall avg throughput: {imgs_per_sec_total:.1f} img/s\")\n",
    "print(f\"Last epoch: #{last_epoch['epoch']} | time={last_epoch['time_sec']:.2f}s | \"\n",
    "      f\"avg_loss={last_epoch['avg_loss']:.4f} | throughput={last_epoch['throughput_img_per_sec']:.1f} img/s \"\n",
    "      f\"| batch_size={last_epoch['batch_size']}\")\n",
    "\n",
    "print(f\"\\nGPU samples CSV: {PARAMS['CSV_PATH']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
